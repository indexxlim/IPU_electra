{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b6829e-91ef-4eb6-8184-20b6ae9e9c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bea51584-30da-49d7-8b15-91bc7c016d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import ElectraTokenizerFast, ElectraForTokenClassification\n",
    "from pprint import pprint\n",
    "\n",
    "tokenizer = ElectraTokenizerFast.from_pretrained(\"monologg/koelectra-small-finetuned-naver-ner\")\n",
    "model = ElectraForTokenClassification.from_pretrained(\"monologg/koelectra-small-finetuned-naver-ner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207ffe60-f4d3-48af-95ce-299423547430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94a4ead-473f-4c21-87e3-ddb0e3c3fdd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b47bfb4-072c-4bd7-ace6-3d3fb396ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Optional, Union\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from transformers import (\n",
    "    BasicTokenizer,\n",
    "    PreTrainedTokenizer,\n",
    "    Pipeline\n",
    ")\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def custom_encode_plus(sentence,\n",
    "                       tokenizer,\n",
    "                       return_tensors=None):\n",
    "    # {'input_ids': [2, 10841, 10966, 10832, 10541, 21509, 27660, 18, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
    "    words = sentence.split()\n",
    "\n",
    "    tokens = []\n",
    "    tokens_mask = []\n",
    "\n",
    "    for word in words:\n",
    "        word_tokens = tokenizer.tokenize(word)\n",
    "        if not word_tokens:\n",
    "            word_tokens = [tokenizer.unk_token]  # For handling the bad-encoded word\n",
    "        tokens.extend(word_tokens)\n",
    "        tokens_mask.extend([1] + [0] * (len(word_tokens) - 1))\n",
    "\n",
    "    ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    len_ids = len(ids)\n",
    "    total_len = len_ids + tokenizer.num_special_tokens_to_add()\n",
    "    if tokenizer.model_max_length and total_len > tokenizer.model_max_length:\n",
    "        ids, _, _ = tokenizer.truncate_sequences(\n",
    "            ids,\n",
    "            pair_ids=None,\n",
    "            num_tokens_to_remove=total_len - tokenizer.model_max_length,\n",
    "            truncation_strategy=\"longest_first\",\n",
    "            stride=0,\n",
    "        )\n",
    "\n",
    "    sequence = tokenizer.build_inputs_with_special_tokens(ids)\n",
    "    token_type_ids = tokenizer.create_token_type_ids_from_sequences(ids)\n",
    "    # HARD-CODED: As I know, most of the transformers architecture will be `[CLS] + text + [SEP]``\n",
    "    #             Only way to safely cover all the cases is to integrate `token mask builder` in internal library.\n",
    "    tokens_mask = [1] + tokens_mask + [1]\n",
    "    words = [tokenizer.cls_token] + words + [tokenizer.sep_token]\n",
    "\n",
    "    encoded_inputs = {}\n",
    "    encoded_inputs[\"input_ids\"] = sequence\n",
    "    encoded_inputs[\"token_type_ids\"] = token_type_ids\n",
    "\n",
    "    encoded_inputs[\"input_ids\"] = torch.tensor([encoded_inputs[\"input_ids\"]])\n",
    "\n",
    "    if \"token_type_ids\" in encoded_inputs:\n",
    "        encoded_inputs[\"token_type_ids\"] = torch.tensor([encoded_inputs[\"token_type_ids\"]])\n",
    "\n",
    "    if \"attention_mask\" in encoded_inputs:\n",
    "        encoded_inputs[\"attention_mask\"] = torch.tensor([encoded_inputs[\"attention_mask\"]])\n",
    "\n",
    "    elif return_tensors is not None:\n",
    "        logger.warning(\n",
    "            \"Unable to convert output to tensors format {}, PyTorch or TensorFlow is not available.\".format(\n",
    "                return_tensors\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return encoded_inputs, words, tokens_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e669c50-37c3-45ea-b7d6-4c515a336776",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46470fcf-6f56-4667-ae80-0640dc1bb78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"2009년 7월 FC서울을 떠나 잉글랜드 프리미어리그 볼턴 원더러스로 이적한 이청용은 크리스탈 팰리스와 독일 분데스리가2 VfL 보훔을 거쳐 지난 3월 K리그로 컴백했다. 행선지는 서울이 아닌 울산이었다\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e9d4cb2-8894-4813-85da-874a424a1170",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens, words, tokens_mask = custom_encode_plus(sentence, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16a864ee-e5bd-4b85-93bf-5bd168b83361",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2, 11909, 11243, 16810, 15953,  5703, 12584, 17085, 30548,  2355,\n",
       "           6134,  3658, 21851, 11184, 15334,  5696,  3777,  5736, 19686, 26772,\n",
       "           5129, 10856,  5813, 11276,  2428, 17804, 10731,  5920,    58,  5988,\n",
       "           6240,  2348,  7462,  5703, 12103, 10563, 11207, 21444,  5699,  4675,\n",
       "           5821, 10542,    18,  5386,  5843, 10639, 10602,  5706, 10940, 13125,\n",
       "          10822,     3]]),\n",
       " 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5ce6798-c884-4044-97b9-66fada088c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6daa7cec-5885-4596-a85e-bbc1589c880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode_plus(sentence,\n",
    "    padding='longest',\n",
    "    max_length=512,\n",
    "    truncation=True, \n",
    "    return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4147f7bb-10ff-4a7c-9278-7cc44f111ba6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd83598a-2352-4359-a72f-f52c99fce178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "882bfdc2-50ff-48b5-8d88-0ca2c93edbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = model(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4e7dc78-54eb-44e4-819d-e0de6a7394f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = entities[0][0].detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10c0ffab-de40-4ab7-a23f-ddb8f68ee72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.exp(result) / np.exp(result).sum(-1, keepdims=True)\n",
    "labels_idx = score.argmax(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bd81ebf-b80c-4e06-aa32-48d414e1dd83",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_level_answer = []\n",
    "input_ids = tokens[\"input_ids\"].numpy()[0]\n",
    "\n",
    "for idx, label_idx in enumerate(labels_idx):\n",
    "    # NOTE Append every answer even though the `entity` is in `ignore_labels`\n",
    "    token_level_answer += [\n",
    "        {\n",
    "            \"word\": tokenizer.convert_ids_to_tokens(int(input_ids[idx])),\n",
    "            \"score\": score[idx][label_idx].item(),\n",
    "            \"entity\": model.config.id2label[label_idx],\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f07e8d3-632c-475b-99d3-d1f7e7f68ead",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4e85e5-d26a-4060-bc31-663630c4ac67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b845847-e184-4dc4-9f3d-cf3e7d04ecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f083b260-6e8f-4238-b413-44358c61a70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/naver-ner/test.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3ad1d4c-69e4-40bf-9d04-c5d29bda686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(data_path, sep='\\t', names = ['text', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03646c58-d03b-406b-bf09-b80b7221402f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c56575a-cab8-48e9-afa3-ce180f880e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08784159-2c62-4ceb-8bbf-2beaddd76958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from dataclasses import dataclass\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6860bc02-892b-44da-bb13-419aa23b7398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc94306a-e37b-4e3d-9036-b58ee4f77750",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        data = pd.read_csv(data_path, sep='\\t', names = ['text', 'label'])\n",
    "        \n",
    "        self.texts = []\n",
    "        self.labels = []\n",
    "        for i in range(len(data)):\n",
    "            self.texts.append(data.iloc[i].text.split())\n",
    "            self.labels.append(data.iloc[i].label)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return {'text':self.texts[index], 'label':self.labels[index]}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9920980c-8c4a-44af-b32f-6f63708f5c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class NERCollator:\n",
    "    def __init__(self, tokenizer, mapping=None):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.text = 'text'\n",
    "        self.label = 'label'\n",
    "        self.pad_token_label_id = -100\n",
    "\n",
    "        labels_lst = [\"O\",\n",
    "                \"PER-B\", \"PER-I\", \"FLD-B\", \"FLD-I\", \"AFW-B\", \"AFW-I\", \"ORG-B\", \"ORG-I\",\n",
    "                \"LOC-B\", \"LOC-I\", \"CVL-B\", \"CVL-I\", \"DAT-B\", \"DAT-I\", \"TIM-B\", \"TIM-I\",\n",
    "                \"NUM-B\", \"NUM-I\", \"EVT-B\", \"EVT-I\", \"ANM-B\", \"ANM-I\", \"PLT-B\", \"PLT-I\",\n",
    "                \"MAT-B\", \"MAT-I\", \"TRM-B\", \"TRM-I\"]\n",
    "        self.labels_dict = {label:i for i, label in enumerate(labels_lst)}\n",
    "\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        if self.text not in batch[0] or self.label not in batch[0]:\n",
    "            raise Exception(\"Error: Undefined data keys\")\n",
    "\n",
    "        sentence = [item[self.text] for item in batch]\n",
    "\n",
    "        source_batch = self.tokenizer.batch_encode_plus(sentence,\n",
    "                    padding='longest',\n",
    "                    is_split_into_words=True,\n",
    "                    max_length=512,\n",
    "                    truncation=True, \n",
    "                    return_offsets_mapping=True,\n",
    "                    return_tensors='pt')\n",
    "\n",
    "        labels = [[self.labels_dict[la] for la in item[self.label].split()] for item in batch]\n",
    "        sequence_length = source_batch.input_ids.shape[1]\n",
    "        labels = [label + [self.pad_token_label_id] * (sequence_length-len(label)) for label in labels]\n",
    "        \n",
    "\n",
    "        return {'input_ids':source_batch.input_ids,\n",
    "                 'attention_mask':source_batch.attention_mask,\n",
    "                 'token_type_ids':source_batch.token_type_ids,\n",
    "                 'labels': labels,\n",
    "                 'offset_mapping': source_batch.offset_mapping,\n",
    "                 'sentence': sentence\n",
    "                 }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3828803b-815f-486a-b689-5adee97fc708",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NERDataset(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e3f1632-138d-4165-9a88-f362cafc3db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = NERCollator(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c7dd167-a5ff-4836-bcc7-5588cfd232b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dataset, batch_size=4, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ab1804b-aae4-4454-9404-ffd7ec4d4278",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6d1e85-170c-44bd-ae78-118da437dd9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d497840-bc64-441c-962e-052fbc3949e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import ElectraTokenizer, ElectraForTokenClassification\n",
    "# import torch\n",
    "\n",
    "# tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-discriminator')\n",
    "# model = ElectraForTokenClassification.from_pretrained('google/electra-small-discriminator')\n",
    "\n",
    "# inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "# labels = torch.tensor([1] * inputs[\"input_ids\"].size(1)).unsqueeze(0)  # Batch size 1\n",
    "\n",
    "# outputs = model(**inputs, labels=labels)\n",
    "# loss, scores = outputs[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7129c34-1768-49f4-ba48-d7282b755f64",
   "metadata": {},
   "source": [
    "# IPU model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "10745535-0d89-4454-b7d0-7df4024659d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d4e2f0c8-465f-4500-88a0-fdfe4a8e3f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easydict import EasyDict\n",
    "import yaml\n",
    "from pipeline_electra import PipelinedElectraForTokenClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2408b423-7a90-4c5e-a301-c609223d31ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"finetune/ner_configurations.yaml\"\n",
    "config = EasyDict(yaml.load(open(config_file).read(), Loader=yaml.Loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "798c844e-cbc1-490f-bdbc-6b4af8ee485c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NERDataset(config.train_data_path)\n",
    "collator = NERCollator(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cd989191-9ef7-49cd-b7ae-74097ab81004",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = DataLoader(dataset, batch_size=4, collate_fn=collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4ea6283a-bfcb-4b3e-93d4-cc833481fdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dce271f-1088-4498-bf33-ee926f28cc7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8fa3b4a1-6bd7-4fe6-9682-7988bed0ad2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing PipelinedElectraForTokenClassification: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing PipelinedElectraForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PipelinedElectraForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of PipelinedElectraForTokenClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#data_path\n",
    "train_ipu_config = {\n",
    "    \"layer_per_ipu\": config.train_config.train_layers_per_ipu,\n",
    "    \"recompute_checkpoint_every_layer\": config.train_config.train_recompute_checkpoint_every_layer,\n",
    "    \"embedding_serialization_factor\": config.train_config.train_embedding_serialization_factor\n",
    "}\n",
    "\n",
    "train_ipu_config = EasyDict(train_ipu_config)\n",
    "model = PipelinedElectraForTokenClassification.from_pretrained_transformers(config.train_config.model_name_or_path, train_ipu_config)\n",
    "\n",
    "# model.parallelize().half().train()\n",
    "\n",
    "train_global_batch_size = config.train_config.train_global_batch_size\n",
    "train_micro_batch_size = config.train_config.train_micro_batch_size\n",
    "train_replication_factor = config.train_config.train_replication_factor\n",
    "gradient_accumulation = int(train_global_batch_size / train_micro_batch_size / train_replication_factor)\n",
    "train_device_iterations = config.train_config.train_device_iterations\n",
    "train_samples_per_iteration = train_global_batch_size * train_device_iterations\n",
    "num_epochs = config.train_config.num_epochs\n",
    "\n",
    "# train_opts = ipu_options(gradient_accumulation, train_replication_factor, train_device_iterations, train_option=True)\n",
    "\n",
    "#train_model = poptorch.trainingModel(model, train_opts, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "03407462-b6fe-48c8-8084-fad59063538b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "ca2b926d-9fc9-431d-ade3-0226b1e5c4a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "embedding(): argument 'indices' (position 2) must be Tensor, not list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-135-f672969e2972>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'token_type_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/IPU_electra/pipeline_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, labels)\u001b[0m\n\u001b[1;32m    526\u001b[0m         }\n\u001b[1;32m    527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mfinal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoptorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"none\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/IPU_electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1263\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1264\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1266\u001b[0m         )\n\u001b[1;32m   1267\u001b[0m         \u001b[0mdiscriminator_sequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator_hidden_states\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/IPU_electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m             \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m         )\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/project/IPU_electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2042\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2043\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2044\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not list"
     ]
    }
   ],
   "source": [
    "model(batch['input_ids'],batch['token_type_ids'],batch['labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95adcac9-06bb-40d8-acd5-3e55a60b5350",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28abb0a4-976e-4318-8bdf-41989713b7d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a653a76e-54e8-4bf1-b1dd-2cda0d668b05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ba03b2f3-a050-4b48-ad6c-85ea1872f7cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-fbea6adc8b2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model(batch['input_ids'],\n\u001b[1;32m      2\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m batch['token_type_ids'])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "model(batch['input_ids'],\n",
    "batch['attention_mask'],\n",
    "batch['token_type_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9370bbac-eb2e-4019-94df-e75481192409",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dcf325-5bc1-40c4-a05f-d9ca6e4f81a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d324e2d2-a189-4fc9-aaf9-f4128947a4b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d8394ad-487e-4857-8515-343d02adeabd",
   "metadata": {},
   "source": [
    "# IPU model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "59f47160-43bc-46eb-a9f7-31fdf650dc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2f68bb9e-28d5-4f98-918f-cea8ada5948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline_electra import PipelinedElectraForTokenClassification\n",
    "from easydict import EasyDict\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "911cb723-ae59-4745-8a0a-1d8f0bae27cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = 'finetune/squad_configurations.yaml'\n",
    "config = EasyDict(yaml.load(open(config_file).read(), Loader=yaml.Loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cf9c24fc-2a9e-46dc-bd3e-44105dfbf0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ipu_config = {\n",
    "    \"layers_per_ipu\": config.train_config.train_layers_per_ipu,\n",
    "    \"recompute_checkpoint_every_layer\": config.train_config.train_recompute_checkpoint_every_layer,\n",
    "    \"embedding_serialization_factor\": config.train_config.train_embedding_serialization_factor\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a639f64a-48f2-4e91-90c1-5c7a76f33cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PipelinedElectraForTokenClassification.from_pretrained_transformers(\"monologg/koelectra-small-finetuned-naver-ner\", train_ipu_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf389f72-b353-42e4-ab48-8fbe9825ffcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51af9167-3107-49f0-9eee-82c3ef9952ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b5f3d80d-ae06-4b4c-852e-52b230e7d74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import poptorch\n",
    "from finetune.run_squad_ipu import ipu_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b91790d9-3108-4de3-b001-5964d3d94363",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_micro_batch_size = 1\n",
    "valid_replication_factor = 1\n",
    "valid_global_batch_size = valid_micro_batch_size * valid_replication_factor\n",
    "valid_device_iterations = 1\n",
    "valid_samples_per_iteration = valid_global_batch_size * valid_device_iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "190c64c9-c203-481c-8034-1b3fa6dfed91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_samples_per_iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f237f996-fbcf-4feb-adea-c8bda9f61d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_opts = ipu_options(1, valid_replication_factor, valid_device_iterations, train_option=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "afcd4feb-355d-42d6-a554-c2fb634516a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = poptorch.inferenceModel(model, val_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8a1d1dd5-4557-442f-8758-00ddaad0d7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#token = tokenizer.encode_plus(sentence, return_tensors='pt', return_offsets_mapping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618038e3-81ef-445b-a543-1b1691119287",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f721b3-81ee-4ef6-8ae7-b95df800e2f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3f3e629d-4234-49e5-aac0-3efcac89c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = sentence.split()\n",
    "split_tokens = tokenizer.encode_plus(word_list, is_split_into_words=True, return_tensors='pt', return_offsets_mapping=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1f1a4a2a-29c1-4f7c-8efb-ac598b7e2ab7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "word_offset_mapping = split_tokens['offset_mapping']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31809ebd-ca9e-4d2e-b41f-fede0b1e02d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "2047807b-32b7-4a0b-aac8-dd3378d187c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input_ids = torch.vstack((token['input_ids'],token['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "86645fa6-12cc-48dd-969d-e11dd25c1c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#token_type_ids = torch.vstack((token['token_type_ids'],token['token_type_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "85063c74-4d41-44b3-a43f-2d3a9afa632d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2, 11909, 11243, 16810, 15953,  5703, 12584, 17085, 30548,  2355,\n",
       "          6134,  3658, 21851, 11184, 15334,  5696,  3777,  5736, 19686, 26772,\n",
       "          5129, 10856,  5813, 11276,  2428, 17804, 10731,  5920,    58,  5988,\n",
       "          6240,  2348,  7462,  5703, 12103, 10563, 11207, 21444,  5699,  4675,\n",
       "          5821, 10542,    18,  5386,  5843, 10639, 10602,  5706, 10940, 13125,\n",
       "         10822,     3]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_tokens['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "67a0b9e4-f3d4-4ee6-974d-0f09a4f7967a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Graph compilation: 100%|██████████| 100/100 [00:01<00:00]\n"
     ]
    }
   ],
   "source": [
    "entities = inference_model(split_tokens['input_ids'], split_tokens['token_type_ids'])#, split_tokens['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce72db1-4537-426c-8c18-da9b905993bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cfea48-d3f7-4e97-80b9-caf66fe7869b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9db7f811-0fac-4f5b-9928-8fc69a754748",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_offset_mapping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8429c2aad811>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mignore_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mword_offset_mapping\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_offset_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mentities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_offset_mapping' is not defined"
     ]
    }
   ],
   "source": [
    "ignore_labels=[\"O\"]\n",
    "ignore_special_tokens=True\n",
    "\n",
    "word_offset_mapping = word_offset_mapping[0].cpu().numpy()\n",
    "entities = entities[0].cpu().numpy()\n",
    "input_ids = split_tokens[\"input_ids\"].numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ade88a7-9c76-46f5-8e87-64a1e402d998",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303e37ef-2aa4-4a2b-a89d-1d6c67e03230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4dad817-d21c-43f3-a6a1-6f184b723b37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca14b8c8-4f48-4c09-ac98-523c5179e351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "39ea0df7-3c92-4079-854f-672faabda6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.exp(entities) / np.exp(entities).sum(-1, keepdims=True)\n",
    "labels_idx = score.argmax(axis=-1)\n",
    "\n",
    "token_level_answer = []\n",
    "for idx, label_idx in enumerate(labels_idx):\n",
    "    if model.config.id2label[label_idx] in ignore_labels:\n",
    "        token_answer = []\n",
    "        continue\n",
    "    \n",
    "    elif word_offset_mapping[idx][0] == 0:\n",
    "        if token_answer:\n",
    "            token_answer[\"word\"] = tokenizer.decode(token_answer[\"word\"])\n",
    "            token_level_answer.append(token_answer)\n",
    "        token_answer = {\n",
    "                \"word\": [int(input_ids[idx])],\n",
    "                \"score\": score[idx][label_idx].item(),\n",
    "                \"entity\": model.config.id2label[label_idx],\n",
    "        }\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        token_answer['word'].append(int(input_ids[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13daad8-415c-4413-9adf-cb2ce96fd323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "4d6f475f-7df4-48aa-8d27-40e7bf957076",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for i, word_offset in enumerate(word_offset_mapping):\n",
    "    if (word_offset[1] - word_offset[0]) == 0:\n",
    "        token = []\n",
    "        continue\n",
    "    elif word_offset[0] == 0:\n",
    "        if token:\n",
    "            tokens.append(token)\n",
    "        token = []\n",
    "        token.append(split_tokens['input_ids'][0][i])\n",
    "    else:\n",
    "        token.append(split_tokens['input_ids'][0][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "12a3a2ec-8bb6-48fd-b37b-f5f3c1ff847c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 5],\n",
       "       [0, 2],\n",
       "       [0, 2],\n",
       "       [2, 4],\n",
       "       [4, 5],\n",
       "       [0, 2],\n",
       "       [0, 4],\n",
       "       [0, 6],\n",
       "       [0, 1],\n",
       "       [1, 2],\n",
       "       [0, 1],\n",
       "       [1, 3],\n",
       "       [3, 5],\n",
       "       [0, 2],\n",
       "       [2, 3],\n",
       "       [0, 1],\n",
       "       [1, 2],\n",
       "       [2, 4],\n",
       "       [0, 4],\n",
       "       [0, 1],\n",
       "       [1, 3],\n",
       "       [3, 4],\n",
       "       [0, 2],\n",
       "       [0, 1],\n",
       "       [1, 3],\n",
       "       [3, 5],\n",
       "       [5, 6],\n",
       "       [0, 1],\n",
       "       [1, 2],\n",
       "       [2, 3],\n",
       "       [0, 1],\n",
       "       [1, 2],\n",
       "       [2, 3],\n",
       "       [0, 2],\n",
       "       [0, 2],\n",
       "       [0, 2],\n",
       "       [0, 3],\n",
       "       [3, 4],\n",
       "       [0, 1],\n",
       "       [1, 2],\n",
       "       [2, 4],\n",
       "       [4, 5],\n",
       "       [0, 1],\n",
       "       [1, 2],\n",
       "       [2, 4],\n",
       "       [0, 2],\n",
       "       [2, 3],\n",
       "       [0, 2],\n",
       "       [0, 2],\n",
       "       [2, 5],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_offset_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "29fd9399-8afe-4d1e-a3c2-bd7c5f6c5226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2009년'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "a57cc14c-bf7a-4139-b45d-2fc851f9da00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009년\n",
      "7월\n",
      "FC서울을\n",
      "떠나\n",
      "잉글랜드\n",
      "프리미어리그\n",
      "볼턴\n",
      "원더러스로\n",
      "이적한\n",
      "이청용은\n",
      "크리스탈\n",
      "팰리스와\n",
      "독일\n",
      "분데스리가2\n",
      "VfL\n",
      "보훔을\n",
      "거쳐\n",
      "지난\n",
      "3월\n",
      "K리그로\n",
      "컴백했다.\n",
      "행선지는\n",
      "서울이\n",
      "아닌\n"
     ]
    }
   ],
   "source": [
    "for token in tokens:\n",
    "    print(tokenizer.decode(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a80acf3-f702-4c43-b4e2-73f88707938c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedaa82c-46de-40e3-84d4-7df45f8fdea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "26757fb4-3f73-4c8f-b4b6-408967e48d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cur_offset_mapping = offset_mapping[0]\n",
    "for i, offset in enumerate(cur_offset_mapping[1:-1]):\n",
    "    #print(offset)\n",
    "    if (cur_offset_mapping[i+1][0] - offset[1]) > 0:\n",
    "        continue\n",
    "    else:\n",
    "        print(token_level_answer[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4037bf49-7b77-4558-944f-0c157ce274ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': '7월', 'score': 0.9350952506065369, 'entity': 'DAT-I'},\n",
       " {'word': 'FC', 'score': 0.9994584321975708, 'entity': 'ORG-B'},\n",
       " {'word': '##서울', 'score': 0.9809041023254395, 'entity': 'ORG-I'},\n",
       " {'word': '##을', 'score': 0.9081450700759888, 'entity': 'O'},\n",
       " {'word': '떠나', 'score': 0.9999575614929199, 'entity': 'O'},\n",
       " {'word': '잉글랜드', 'score': 0.9983227849006653, 'entity': 'LOC-B'},\n",
       " {'word': '프리미어리그', 'score': 0.9989780187606812, 'entity': 'ORG-B'},\n",
       " {'word': '볼', 'score': 0.9300729632377625, 'entity': 'ORG-B'},\n",
       " {'word': '##턴', 'score': 0.9710206389427185, 'entity': 'ORG-I'},\n",
       " {'word': '원', 'score': 0.999349057674408, 'entity': 'ORG-I'},\n",
       " {'word': '##더러', 'score': 0.9925868511199951, 'entity': 'ORG-I'},\n",
       " {'word': '##스로', 'score': 0.9959636926651001, 'entity': 'ORG-I'},\n",
       " {'word': '이적', 'score': 0.9999213814735413, 'entity': 'O'},\n",
       " {'word': '##한', 'score': 0.9999334216117859, 'entity': 'O'},\n",
       " {'word': '이', 'score': 0.9994910359382629, 'entity': 'PER-B'},\n",
       " {'word': '##청', 'score': 0.7056900262832642, 'entity': 'PER-B'},\n",
       " {'word': '##용은', 'score': 0.5724880695343018, 'entity': 'PER-B'},\n",
       " {'word': '크리스탈', 'score': 0.9994640350341797, 'entity': 'ORG-B'},\n",
       " {'word': '팰', 'score': 0.9991778135299683, 'entity': 'ORG-I'},\n",
       " {'word': '##리스', 'score': 0.9978461265563965, 'entity': 'ORG-I'},\n",
       " {'word': '##와', 'score': 0.9522739052772522, 'entity': 'O'},\n",
       " {'word': '독일', 'score': 0.9977171421051025, 'entity': 'LOC-B'},\n",
       " {'word': '분', 'score': 0.9814788699150085, 'entity': 'ORG-B'},\n",
       " {'word': '##데스', 'score': 0.8572928309440613, 'entity': 'ORG-B'},\n",
       " {'word': '##리가', 'score': 0.9942399859428406, 'entity': 'ORG-I'},\n",
       " {'word': '##2', 'score': 0.9120205640792847, 'entity': 'ORG-I'},\n",
       " {'word': 'V', 'score': 0.8719519376754761, 'entity': 'ORG-B'},\n",
       " {'word': '##f', 'score': 0.7203494310379028, 'entity': 'ORG-I'},\n",
       " {'word': '##L', 'score': 0.9656755328178406, 'entity': 'ORG-I'},\n",
       " {'word': '보', 'score': 0.9938763380050659, 'entity': 'ORG-I'},\n",
       " {'word': '##훔', 'score': 0.9126798510551453, 'entity': 'ORG-I'},\n",
       " {'word': '##을', 'score': 0.6827937960624695, 'entity': 'O'},\n",
       " {'word': '거쳐', 'score': 0.9999727606773376, 'entity': 'O'},\n",
       " {'word': '지난', 'score': 0.9963383078575134, 'entity': 'DAT-B'},\n",
       " {'word': '3월', 'score': 0.9909418225288391, 'entity': 'DAT-I'},\n",
       " {'word': 'K리그', 'score': 0.9995406270027161, 'entity': 'ORG-B'},\n",
       " {'word': '##로', 'score': 0.9990398287773132, 'entity': 'O'},\n",
       " {'word': '컴', 'score': 0.9999098181724548, 'entity': 'O'},\n",
       " {'word': '##백', 'score': 0.998866856098175, 'entity': 'O'},\n",
       " {'word': '##했다', 'score': 0.9999646544456482, 'entity': 'O'},\n",
       " {'word': '.', 'score': 0.9999403357505798, 'entity': 'O'},\n",
       " {'word': '행', 'score': 0.9993055462837219, 'entity': 'O'},\n",
       " {'word': '##선', 'score': 0.9969778656959534, 'entity': 'O'},\n",
       " {'word': '##지는', 'score': 0.9959809184074402, 'entity': 'O'},\n",
       " {'word': '서울', 'score': 0.9918311238288879, 'entity': 'ORG-B'},\n",
       " {'word': '##이', 'score': 0.9753754138946533, 'entity': 'O'},\n",
       " {'word': '아닌', 'score': 0.9999187588691711, 'entity': 'O'},\n",
       " {'word': '울산', 'score': 0.9994460940361023, 'entity': 'ORG-B'}]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_level_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e4558a63-be2d-4619-affb-ca5f25405071",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_labels=[\"O\"]\n",
    "ignore_special_tokens=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d6b55a34-e27d-4e85-8b77-729e521860aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [FIX] Now let's change it to word-level NER\n",
    "word_idx = 0\n",
    "word_level_answer = []\n",
    "\n",
    "# NOTE: Might not be safe. BERT, ELECTRA etc. won't make issues.\n",
    "if ignore_special_tokens:\n",
    "    words = words[1:-1]\n",
    "    tokens_mask = tokens_mask[1:-1]\n",
    "    token_level_answer = token_level_answer[1:-1]\n",
    "\n",
    "for mask, ans in zip(tokens_mask, token_level_answer):\n",
    "    if mask == 1:\n",
    "        ans[\"word\"] = words[word_idx]\n",
    "        word_idx += 1\n",
    "        if ans[\"entity\"] not in ignore_labels:\n",
    "            word_level_answer.append(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd73eea1-5ad0-4fe4-80e7-f43ba82399c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "4e39f1ce-ddc2-4214-a29a-fce7a341addc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " '2009년',\n",
       " '7월',\n",
       " 'FC서울을',\n",
       " '떠나',\n",
       " '잉글랜드',\n",
       " '프리미어리그',\n",
       " '볼턴',\n",
       " '원더러스로',\n",
       " '이적한',\n",
       " '이청용은',\n",
       " '크리스탈',\n",
       " '팰리스와',\n",
       " '독일',\n",
       " '분데스리가2',\n",
       " 'VfL',\n",
       " '보훔을',\n",
       " '거쳐',\n",
       " '지난',\n",
       " '3월',\n",
       " 'K리그로',\n",
       " '컴백했다.',\n",
       " '행선지는',\n",
       " '서울이',\n",
       " '아닌',\n",
       " '울산이었다',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e37fca02-250f-44a1-b9e1-570e8320c542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'word': '2009년', 'score': 0.9996205568313599, 'entity': 'DAT-B'},\n",
       " {'word': '7월', 'score': 0.9350952506065369, 'entity': 'DAT-I'},\n",
       " {'word': 'FC', 'score': 0.9994584321975708, 'entity': 'ORG-B'},\n",
       " {'word': '##서울', 'score': 0.9809041023254395, 'entity': 'ORG-I'},\n",
       " {'word': '잉글랜드', 'score': 0.9983227849006653, 'entity': 'LOC-B'},\n",
       " {'word': '프리미어리그', 'score': 0.9989780187606812, 'entity': 'ORG-B'},\n",
       " {'word': '볼', 'score': 0.9300729632377625, 'entity': 'ORG-B'},\n",
       " {'word': '##턴', 'score': 0.9710206389427185, 'entity': 'ORG-I'},\n",
       " {'word': '원', 'score': 0.999349057674408, 'entity': 'ORG-I'},\n",
       " {'word': '##더러', 'score': 0.9925868511199951, 'entity': 'ORG-I'},\n",
       " {'word': '##스로', 'score': 0.9959636926651001, 'entity': 'ORG-I'},\n",
       " {'word': '이', 'score': 0.9994910359382629, 'entity': 'PER-B'},\n",
       " {'word': '##청', 'score': 0.7056900262832642, 'entity': 'PER-B'},\n",
       " {'word': '##용은', 'score': 0.5724880695343018, 'entity': 'PER-B'},\n",
       " {'word': '크리스탈', 'score': 0.9994640350341797, 'entity': 'ORG-B'},\n",
       " {'word': '팰', 'score': 0.9991778135299683, 'entity': 'ORG-I'},\n",
       " {'word': '##리스', 'score': 0.9978461265563965, 'entity': 'ORG-I'},\n",
       " {'word': '독일', 'score': 0.9977171421051025, 'entity': 'LOC-B'},\n",
       " {'word': '분', 'score': 0.9814788699150085, 'entity': 'ORG-B'},\n",
       " {'word': '##데스', 'score': 0.8572928309440613, 'entity': 'ORG-B'},\n",
       " {'word': '##리가', 'score': 0.9942399859428406, 'entity': 'ORG-I'},\n",
       " {'word': '##2', 'score': 0.9120205640792847, 'entity': 'ORG-I'},\n",
       " {'word': 'V', 'score': 0.8719519376754761, 'entity': 'ORG-B'},\n",
       " {'word': '##f', 'score': 0.7203494310379028, 'entity': 'ORG-I'},\n",
       " {'word': '##L', 'score': 0.9656755328178406, 'entity': 'ORG-I'},\n",
       " {'word': '보', 'score': 0.9938763380050659, 'entity': 'ORG-I'},\n",
       " {'word': '##훔', 'score': 0.9126798510551453, 'entity': 'ORG-I'},\n",
       " {'word': '지난', 'score': 0.9963383078575134, 'entity': 'DAT-B'},\n",
       " {'word': '3월', 'score': 0.9909418225288391, 'entity': 'DAT-I'},\n",
       " {'word': 'K리그', 'score': 0.9995406270027161, 'entity': 'ORG-B'},\n",
       " {'word': '서울', 'score': 0.9918311238288879, 'entity': 'ORG-B'},\n",
       " {'word': '울산', 'score': 0.9994460940361023, 'entity': 'ORG-B'}]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_level_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e844f611-b246-4b09-8b75-4440e2c4f327",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b445bb-411e-4999-a7b1-125736b2f3c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
