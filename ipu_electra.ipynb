{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6adaa0-88bb-4003-9b51-2bd1519c7836",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe798ffd-1ac3-459e-9bf5-696efe002cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from easydict import EasyDict\n",
    "\n",
    "import torch\n",
    "from transformers import ElectraTokenizer#, ElectraModel\n",
    "from optimum.graphcore import IPUSeq2SeqTrainingArguments as Seq2SeqTrainingArguments\n",
    "\n",
    "from modeling_electra import ElectraModel, ElectraForMaskedLM\n",
    "from ipu_configuration import IPUConfig, ipu_options\n",
    "import inspect\n",
    "\n",
    "\n",
    "tokenizer = ElectraTokenizer.from_pretrained('google/electra-small-generator')\n",
    "model = ElectraForMaskedLM.from_pretrained('google/electra-small-generator')\n",
    "\n",
    "input_ids = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")[\"input_ids\"]\n",
    "\n",
    "outputs = model(input_ids, labels=input_ids)\n",
    "loss, prediction_scores = outputs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bead9c0-4702-4d48-8825-a5d42d2e83da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63d2e59-5cd6-472e-8998-afafc57565db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e48c45b-5083-439c-b151-a3abf9bf6ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_value = tokenizer.encode_plus(\"Hello, my dog is cute\", return_tensors=\"pt\", padding=\"max_length\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f9a3d53-555f-4bc4-adcc-9e58ed90d4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskedLMOutput(loss=None, logits=tensor([[[ 11.1353,  -7.4241,  -7.4119,  ...,  -7.4380,  -7.4108,  -7.3961],\n",
       "         [ -9.8389, -10.2289, -10.2246,  ..., -10.2524, -10.2351, -10.0815],\n",
       "         [  3.9714, -10.9872, -10.9838,  ..., -10.9641, -10.9766, -10.8934],\n",
       "         ...,\n",
       "         [ 50.3298,   1.1282,   1.1599,  ...,   1.0819,   1.2214,   1.1251],\n",
       "         [ 49.8866,   0.8877,   0.9184,  ...,   0.8425,   0.9800,   0.8855],\n",
       "         [ 11.1366,  -7.4236,  -7.4115,  ...,  -7.4376,  -7.4104,  -7.3956]]],\n",
       "       grad_fn=<AddBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**input_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b0f3fbd-e169-4ed5-a3b4-660db7abd08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import BertConfig, ElectraConfig\n",
    "# bert_config = BertConfig.from_pretrained('bert-base-uncased')\n",
    "# electra_config = ElectraConfig.from_pretrained('google/electra-small-discriminator')\n",
    "# print(bert_config)\n",
    "# print(electra_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29eb834f-3f70-42f5-bf6d-8255e001e076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Signature (input_ids:Union[torch.Tensor, NoneType]=None, attention_mask:Union[torch.Tensor, NoneType]=None, token_type_ids:Union[torch.Tensor, NoneType]=None, position_ids:Union[torch.Tensor, NoneType]=None, head_mask:Union[torch.Tensor, NoneType]=None, inputs_embeds:Union[torch.Tensor, NoneType]=None, labels:Union[torch.Tensor, NoneType]=None, output_attentions:Union[bool, NoneType]=None, output_hidden_states:Union[bool, NoneType]=None, return_dict:Union[bool, NoneType]=None) -> Union[Tuple, transformers.modeling_outputs.MaskedLMOutput]>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signature = inspect.signature(model.forward)\n",
    "signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c7a013-1453-4012-9ef5-3157c4f7e870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "147fc275-515f-49ad-aa03-4152b8c80ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__init__.py\t\t  data\t\t\tipu_electra.ipynb\n",
      "__pycache__\t\t  exe_cache\t\tipu_train.py\n",
      "bert_test.ipynb\t\t  finetune\t\tmodeling_electra.py\n",
      "checkpoints\t\t  inference.py\t\tpipeline_electra.py\n",
      "configuration_electra.py  input.txt\t\tserver.py\n",
      "configurations\t\t  ipu_configuration.py\ttest.py\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e143311-ad51-4767-9c56-0577d67ef0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model error\n",
    "#pipelinedElectraForMaskedLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9c6bb2-a26b-4988-8fd9-b7d8bfa6ff08",
   "metadata": {},
   "source": [
    "# IPU Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f82746ed-1718-419a-b163-8e2e0ab78ee8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'pipelinedElectraForMaskedLM'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1b8bbcdff158>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpipeline_electra\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpipelinedElectraForMaskedLM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'pipelinedElectraForMaskedLM'"
     ]
    }
   ],
   "source": [
    "from pipeline_electra import pipelinedElectraForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e44f28e2-bc36-4c68-8649-ba82dda1afdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ipu_config = {\n",
    "    \"layers_per_ipu\": [2,3,4,3],\n",
    "    \"recompute_checkpoint_every_layer\":True,\n",
    "    \"embedding_serialization_factor\": 1\n",
    "}\n",
    "\n",
    "train_ipu_config = EasyDict(train_ipu_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b54a786-62b0-48c8-aae1-aa63eb23b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipu_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b53d76e4-7d8a-4788-b0dd-933357c21ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting replicated_tensor_sharding to False when replication_factor=1\n"
     ]
    }
   ],
   "source": [
    "opts = ipu_config.to_options()\n",
    "\n",
    "optimizer_class = torch.optim.AdamW\n",
    "optimizer = optimizer_class(model.parameters(), lr=0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d73338-dbf8-423c-b835-29545430d36a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "615683d8-b87f-4a27-97a7-77e6c3237000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 128, padding_idx=0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a639cc8b-8df9-4c5a-b2e5-a2a782953332",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline_electra import PipelinedElectraForMaskedLM, PipelinedElectraModel, _PRETRAINED_TO_PIPELINED_REGISTRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ffac13c2-e116-4017-9451-341f72aeedce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ipu_model = PipelinedElectraForMaskedLM.from_transformers(model, ipu_config)\n",
    "ipu_model = WrappedModel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "202432b3-012f-43e8-b67a-3074496532a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opts.toDict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d07684a-62a3-4842-b86c-edac9a338ecf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294f662b-4d4a-478b-aa1a-afb95c42d357",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01578e3-d8ec-4f68-86a1-78e10d52a3e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02802413-94c7-4d55-aa4c-a62a0441d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuple_data = (input_value['input_ids'], input_value['token_type_ids'])#, input_value['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "065fb6a8-9cec-4ae9-b33a-3fe2d31f63ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " tensor([[[ 54.9057,  -5.3235,  -5.2913,  ...,  -5.3311,  -5.2803,  -5.2297],\n",
       "          [  4.3153,  -7.6142,  -7.5974,  ...,  -7.6405,  -7.5978,  -7.4839],\n",
       "          [  0.6850, -10.1405, -10.1285,  ..., -10.1082, -10.1080, -10.0778],\n",
       "          ...,\n",
       "          [ 51.8493,  -6.1342,  -6.1186,  ...,  -6.1448,  -6.0973,  -6.0254],\n",
       "          [ 51.9255,  -5.9819,  -5.9638,  ...,  -5.9926,  -5.9437,  -5.8599],\n",
       "          [ 54.9085,  -5.3233,  -5.2912,  ...,  -5.3309,  -5.2801,  -5.2295]]],\n",
       "        grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipu_model(*tuple_data)#**input_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26e599a-5238-4ded-8475-5d380d501d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5bfc6c9-abe8-45f9-a09e-54ce44c0826f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from finetune.run_squad_ipu import ipu_options\n",
    "val_opts = ipu_options(1, 1, 1, train_option=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d4761249-b235-4e7a-b8cf-7ecd40d88835",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_model = poptorch.trainingModel(ipu_model.train(), options=opts, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "276b3c53-aa1e-4949-8f03-e18eaeb59ba7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Tracer cannot infer type of (tensor([[  101,  7592,  1010,  2026,  3899,  2003, 10140,   102,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0]]), <class 'inspect._empty'>)\n:Only tensors and (possibly nested) tuples of tensors, lists, or dictsare supported as inputs or outputs of traced functions, but instead got value of type type.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-94863b6a0973>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/poptorch/_poplar_executor.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m             )\n\u001b[1;32m    621\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mloadExecutable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/poptorch/_poplar_executor.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(self, in_tensors)\u001b[0m\n\u001b[1;32m    482\u001b[0m                 trace_args = self._trace_model_and_get_compile_args(\n\u001b[1;32m    483\u001b[0m                     \u001b[0min_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tensors_trace_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_converted_any_half\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m                     narrow_tensor_fn)\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m             \u001b[0;31m# Note: in single process execution or if the cache is disabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/poptorch/_poplar_executor.py\u001b[0m in \u001b[0;36m_trace_model_and_get_compile_args\u001b[0;34m(self, in_tensors, in_tensors_trace_view, has_converted_any_half, narrow_tensor_fn)\u001b[0m\n\u001b[1;32m   1188\u001b[0m                 \u001b[0madded_dummy_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1189\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_error_on_buffer_parameter_address_change\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuff_param_addresses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/poptorch/_poplar_executor.py\u001b[0m in \u001b[0;36m_trace_model_and_get_compile_args\u001b[0;34m(self, in_tensors, in_tensors_trace_view, has_converted_any_half, narrow_tensor_fn)\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m             self._trace = self._trace_with_warning_filter(\n\u001b[0;32m-> 1183\u001b[0;31m                 in_tensors_trace_view_tuple)\n\u001b[0m\u001b[1;32m   1184\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m\"didn't return any values\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/poptorch/_poplar_executor.py\u001b[0m in \u001b[0;36m_trace_with_warning_filter\u001b[0;34m(self, in_tensors_trace_view_tuple)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                         \u001b[0;34mf\"Lists and Tuples of Tensors (Got types: {types}).\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                     ).with_traceback(e.__traceback__)\n\u001b[0;32m-> 1039\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/poptorch/_poplar_executor.py\u001b[0m in \u001b[0;36m_trace_with_warning_filter\u001b[0;34m(self, in_tensors_trace_view_tuple)\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m                 traced = torch.jit.trace(self._model,\n\u001b[0;32m-> 1028\u001b[0;31m                                          in_tensors_trace_view_tuple)\n\u001b[0m\u001b[1;32m   1029\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1030\u001b[0m                 \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'Type \\'Tuple(\\[.*\\])\\' cannot be traced'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m             \u001b[0m_module_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m         )\n\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/jit/_trace.py\u001b[0m in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    963\u001b[0m                 \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                 \u001b[0m_force_outplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                 \u001b[0margument_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m             )\n\u001b[1;32m    967\u001b[0m             \u001b[0mcheck_trace_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Tracer cannot infer type of (tensor([[  101,  7592,  1010,  2026,  3899,  2003, 10140,   102,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n             0,     0]]), <class 'inspect._empty'>)\n:Only tensors and (possibly nested) tuples of tensors, lists, or dictsare supported as inputs or outputs of traced functions, but instead got value of type type."
     ]
    }
   ],
   "source": [
    "t_model.compile(input_value['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8faa16b2-0e07-471b-b147-a004ae28cbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_value['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79428b3-4929-4020-954d-c3f7b77f295e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f18363-5d25-4c0d-b723-0ea0d03e111f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "63ad78b1-95f7-4c53-a645-24741803478e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraLayer(\n",
       "  (attention): ElectraAttention(\n",
       "    (self): ElectraSelfAttention(\n",
       "      (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (output): ElectraSelfOutput(\n",
       "      (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (intermediate): ElectraIntermediate(\n",
       "    (dense): Linear(in_features=256, out_features=1024, bias=True)\n",
       "    (intermediate_act_fn): GELUActivation()\n",
       "  )\n",
       "  (output): ElectraOutput(\n",
       "    (dense): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    (LayerNorm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.electra.encoder.layer[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9be6fa8-5224-4de8-9b97-5fc42dd71470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b69de-5533-4d2b-ae4c-28459a401b36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0aed1a-584e-4ded-b8ee-cc959037b6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58008d30-5e95-4d7a-8576-9a3c7d3a4fc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04eee011-bb3a-4e21-a7f0-be777e2381c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402eb5cd-0a35-4fc6-bcdd-cfb9469c6d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87bb0e8f-cdfa-4c75-bf46-169b005cf02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d338c361-9342-4cb1-a6d0-24944bb2e274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 1115394 characters, 65 unique.\n"
     ]
    }
   ],
   "source": [
    "class CharDataset(Dataset):\n",
    "    def __init__(self, data, block_size):\n",
    "        chars = sorted(list(set(data)))\n",
    "        data_size, vocab_size = len(data), len(chars)\n",
    "        print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "\n",
    "        self.stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "        self.itos = {i: ch for i, ch in enumerate(chars)}\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.block_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # grab a chunk of (block_size + 1) characters from the data\n",
    "        chunk = self.data[idx:idx + self.block_size + 1]\n",
    "        # encode every character to an integer\n",
    "        dix = [self.stoi[s] for s in chunk]\n",
    "        x = torch.tensor(dix[:-1], dtype=torch.long)\n",
    "        y = torch.tensor(dix[1:], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "\n",
    "block_size = 128  # spatial extent of the model for its context\n",
    "if not os.path.isfile('input.txt'):\n",
    "    os.system('wget https://github.com/karpathy/char-rnn/raw/master/data/tinyshakespeare/input.txt')\n",
    "text = open('input.txt', 'r').read()  # don't worry we won't run out of file handles\n",
    "train_dataset = CharDataset(text, block_size)  # one line of poem is roughly 50 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b3108ec-1678-4caa-a165-e81c65cb04fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
       "         53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
       "          1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
       "         57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
       "          6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
       "         58, 47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,\n",
       "          1, 56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58,\n",
       "         53,  1]),\n",
       " tensor([47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44, 53,\n",
       "         56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,  1,\n",
       "         44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1, 57,\n",
       "         54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,  6,\n",
       "          1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47, 58,\n",
       "         47, 64, 43, 52, 10,  0, 37, 53, 59,  1, 39, 56, 43,  1, 39, 50, 50,  1,\n",
       "         56, 43, 57, 53, 50, 60, 43, 42,  1, 56, 39, 58, 46, 43, 56,  1, 58, 53,\n",
       "          1, 42]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "069fa662-1743-4918-82f2-2624b817c688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[  101,  7592,  1010,  2026,  3899,  2003, 10140,   102]]),\n",
       " tensor([[0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " tensor([[1, 1, 1, 1, 1, 1, 1, 1]]))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d9ba28-6234-4db9-8a7c-fb27b9c1e9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495e38e4-a3ff-494e-a3f2-66e318b7149f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
