{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "086030c3-aca6-4f7f-baa0-baee95d9da70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM, BertForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "# model = BertForMaskedLM.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# inputs = tokenizer(\"The capital of France is [MASK].\", return_tensors=\"pt\")\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     logits = model(**inputs).logits\n",
    "\n",
    "# # retrieve index of [MASK]\n",
    "# mask_token_index = (inputs.input_ids == tokenizer.mask_token_id)[0].nonzero(as_tuple=True)[0]\n",
    "\n",
    "# predicted_token_id = logits[0, mask_token_index].argmax(axis=-1)\n",
    "# tokenizer.decode(predicted_token_id)\n",
    "\n",
    "# labels = tokenizer(\"The capital of France is Paris.\", return_tensors=\"pt\")[\"input_ids\"]\n",
    "# # mask labels of non-[MASK] tokens\n",
    "# labels = torch.where(inputs.input_ids == tokenizer.mask_token_id, labels, -100)\n",
    "\n",
    "# outputs = model(**inputs, labels=labels)\n",
    "# round(outputs.loss.item(), 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dca4a272-7a35-4cd1-b621-e948c822287c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", problem_type=\"multi_label_classification\", num_labels=3)\n",
    "inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93460465-1662-4b84-8ca3-deb6edc734f7",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BertForSequenceClassification' object has no attribute 'max_seq_len'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f140eb9dc10b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1178\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BertForSequenceClassification' object has no attribute 'max_seq_len'"
     ]
    }
   ],
   "source": [
    "model.max_seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926eefff-13cc-4d46-8889-6ca5111a682b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c681fdd-4ae3-4f17-a4b6-4abfe258dce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25c8b708-4e16-4451-bb98-3105789614f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from easydict import EasyDict\n",
    "from optimum.graphcore import IPUSeq2SeqTrainingArguments as Seq2SeqTrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6592cb49-d5e2-4a8b-8b13-071c9b941dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "argus = {}\n",
    "with open('configurations/electra.yaml') as f:\n",
    "    hparams = yaml.load_all(f, Loader=yaml.FullLoader)\n",
    "    for argu in hparams:\n",
    "        argus[list(argu.keys())[0]]=list(argu.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95fc3e14-a6de-4a87-a188-fde7cdf1d030",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args, data_args, training_args = argus['ModelArguments'], argus['DataTrainingArguments'], argus['IPUSeq2SeqTrainingArguments']\n",
    "model_args, data_args = EasyDict(model_args), EasyDict(data_args)\n",
    "training_args = Seq2SeqTrainingArguments(**training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6f23cc-72ad-485f-9515-f34e8e0873cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7028692-c8ab-4ad1-b970-29a00743bb3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1272540-0448-495c-9032-ccc7a39d257b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimum.graphcore.models.bert.modeling_bert import PipelinedBertForMaskedLM, PipelinedBertForSequenceClassification\n",
    "from optimum.graphcore import IPUConfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da780554-be4e-4dad-8c47-86c259f97cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipu_config = IPUConfig.from_pretrained('configurations/electra_ipu.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78085a04-bc07-4bdf-9b1c-e3e44753ca47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipu_model = PipelinedBertForSequenceClassification.from_transformers(model, ipu_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee4e04da-145f-47b2-96d8-7b2f4678ea69",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipu_model.parallelize()\n",
    "if not training_args.fp32:\n",
    "    ipu_model = ipu_model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641f01df-ddd4-4c2b-81eb-e351bf701697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d513569d-ef6f-4b56-909f-d5b741ecadeb",
   "metadata": {},
   "source": [
    "# GLUE datatest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9c01967-25ac-40a2-9186-2f3d5b5274a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    EvalPrediction,\n",
    "    HfArgumentParser,\n",
    "    PretrainedConfig,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b23841a3-0690-4578-a345-81db962d99c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_to_keys = {\n",
    "    \"cola\": (\"sentence\", None),\n",
    "    \"mnli\": (\"premise\", \"hypothesis\"),\n",
    "    \"mrpc\": (\"sentence1\", \"sentence2\"),\n",
    "    \"qnli\": (\"question\", \"sentence\"),\n",
    "    \"qqp\": (\"question1\", \"question2\"),\n",
    "    \"rte\": (\"sentence1\", \"sentence2\"),\n",
    "    \"sst2\": (\"sentence\", None),\n",
    "    \"stsb\": (\"sentence1\", \"sentence2\"),\n",
    "    \"wnli\": (\"sentence1\", \"sentence2\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dd8916f3-e432-4d42-94e7-b4135787026c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "345d621c-0b22-491f-81d0-cabca38d9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_datasets = load_dataset(\"glue\", 'mnli', cache_dir=model_args.cache_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "082df51b-9470-40cf-b379-610f0142b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_list = raw_datasets[\"train\"].unique(\"label\")\n",
    "# label_list.sort()  # Let's sort it for determinism\n",
    "# num_labels = len(label_list)\n",
    "\n",
    "# sentence1_key, sentence2_key = task_to_keys['mnli']\n",
    "# padding=False\n",
    "# max_seq_length = tokenizer.model_max_length\n",
    "# label_to_id = PretrainedConfig(num_labels=num_labels).label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3168eb86-269c-4d91-a8f0-b9cfb153840b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493b07be-e721-48a4-94c2-5d478b813eab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f24f41-f9a2-40db-a2e8-4553955bc3b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94d1bf3-bacf-48ec-9cf5-7a72947fa54a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7042e590-5bb3-473d-bbb8-cb0412775152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1c21eea-b6e1-40cb-beda-7221889b6bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    # Tokenize the texts\n",
    "    args = (\n",
    "        (examples[sentence1_key],) if sentence2_key is None else (examples[sentence1_key], examples[sentence2_key])\n",
    "    )\n",
    "    result = tokenizer(*args, padding=padding, max_length=max_seq_length, truncation=True)\n",
    "\n",
    "    # Map labels to IDs (not necessary for GLUE tasks)\n",
    "    if label_to_id is not None and \"label\" in examples:\n",
    "        result[\"label\"] = examples[\"label\"]\n",
    "        #result[\"label\"] = [(label_to_id[l] if l != -1 else -1) for l in examples[\"label\"]]\n",
    "    return result\n",
    "\n",
    "# with training_args.main_process_first(desc=\"dataset map pre-processing\"):\n",
    "#     raw_datasets = raw_datasets.map(\n",
    "#         preprocess_function,\n",
    "#         batched=True,\n",
    "#         load_from_cache_file=not data_args.overwrite_cache,\n",
    "#         desc=\"Running tokenizer on dataset\",\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50a4e5d5-9569-4230-b5e9-cebf931447de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = raw_datasets['train']\n",
    "\n",
    "# import inspect\n",
    "\n",
    "# signature = inspect.signature(training_model.forward)\n",
    "# _signature_columns = list(signature.parameters.keys())\n",
    "# _signature_columns += [\"label\", \"label_ids\"]\n",
    "\n",
    "# columns = [k for k in _signature_columns if k in train_dataset.column_names]\n",
    "# ignored_columns = list(set(train_dataset.column_names) - set(_signature_columns))\n",
    "\n",
    "# train_dataset = train_dataset.remove_columns(ignored_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefcb042-5c70-4545-b241-12a53025d882",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15b7eb0c-2de5-414a-9672-3773e4b1fa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import poptorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c585daa6-41aa-46d6-943f-0b028cd51fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting replicated_tensor_sharding to False when replication_factor=1\n"
     ]
    }
   ],
   "source": [
    "opts = ipu_config.to_options()\n",
    "optimizer_class = torch.optim.AdamW\n",
    "optimizer = optimizer_class(model.parameters(), lr=0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bac4988a-1bfa-4bc0-b197-72dd09f4ce09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<poptorch.options.Options at 0x7f4ee46668d0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opts.deviceIterations(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1301a9a6-f0b8-4f6a-9226-140c1ea481ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model = poptorch.trainingModel(\n",
    "    ipu_model.train(), options=opts, optimizer=optimizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9f11d6-7574-4434-bb7e-441b6de7324d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6efad8-84a2-40ef-ba44-a5b6360d1a26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d534a1-57f3-4b3a-b663-0b23d459365e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523ee195-3dbc-4bb1-85ad-208ed8d7c7fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9bb335d-9d10-4d76-8418-830995b539f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model(**{'input_ids':torch.tensor([data['input_ids']]), 'token_type_ids':torch.tensor([data['token_type_ids']]), 'attention_mask':torch.tensor([data['attention_mask']])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68a82f8a-e103-4d19-8762-104b4af1af0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training_model.compile(**{'input_ids':torch.tensor([data['input_ids']]), 'token_type_ids':torch.tensor([data['token_type_ids']]), 'attention_mask':torch.tensor([data['attention_mask']])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94b73b42-8985-462a-b9ac-2e22dd06807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputss = tokenizer([\"Hello, my dog is cute\"]*4, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ac8738-b63f-434b-b5f8-0d3fdb47c77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model.compile(**dict(inputss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1499974-b876-4b7d-a24d-6f3778ccc8f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c27a8658-9d76-465c-95de-afc4b9ba9513",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b1af46e0-568d-4eef-9c82-fa9019d92773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  7592,  1010,  2026,  3899,  2003, 10140,   102],\n",
       "        [  101,  7592,  1010,  2026,  3899,  2003, 10140,   102],\n",
       "        [  101,  7592,  1010,  2026,  3899,  2003, 10140,   102],\n",
       "        [  101,  7592,  1010,  2026,  3899,  2003, 10140,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
       "        [1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890d4fe2-bd9d-43e1-907c-16d22e57ad00",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_model = poptorch.inferenceModel(\n",
    "    ipu_model.eval(), options=opts\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f57bc19b-676e-47b5-84e0-9700aa460126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0570,  0.0084,  0.0037]], dtype=torch.float16),)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_model(**dict(inputss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "061b3004-30f7-457d-83a8-a7d197130a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference_model(**{'input_ids':torch.tensor([data['input_ids']]), 'token_type_ids':torch.tensor([data['token_type_ids']]), 'attention_mask':torch.tensor([data['attention_mask']])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e3a64e-6a1d-43d4-93c2-0d704f57a702",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6f2462-3ec9-4023-b98f-439408bae843",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
